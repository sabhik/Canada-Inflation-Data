{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uxeNIcEPB5a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4713d8-62e7-47da-e6ca-e9ce4f95ca4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n",
            "Current date: 2025-09-25 12:51:12\n",
            "================================================================================\n",
            "COMPLETE CANADIAN GROCERY PRICE TRACKER - WITH GUARANTEED STATCAN EXPORT\n",
            "================================================================================\n",
            "Loaded 312 historical price records\n",
            "\n",
            "Generating historical prices based on Statistics Canada inflation data...\n",
            "Generated 288 historical price points\n",
            "\n",
            "Starting comprehensive price scraping...\n",
            "This version will attempt to scrape ALL prices online first\n",
            "Fallback prices only used when scraping fails\n",
            "Starting enhanced grocery price scraping...\n",
            "============================================================\n",
            "\n",
            "--- Scraping Walmart ---\n",
            "Progress: 1/36\n",
            "Scraping Milk 2% 4L from Walmart...\n",
            "  Attempting to scrape Walmart price for Milk 2% 4L...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 11.7 seconds before retry...\n",
            "    SUCCESS: Found price $6.25 on attempt 2\n",
            "  SUCCESS: Live scraped price $6.25\n",
            "  Waiting 10.3s before next product...\n",
            "Progress: 2/36\n",
            "Scraping Large Eggs 18-pack from Walmart...\n",
            "  Attempting to scrape Walmart price for Large Eggs 18-pack...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 8.8 seconds before retry...\n",
            "    SUCCESS: Found price $6.88 on attempt 2\n",
            "  SUCCESS: Live scraped price $6.88\n",
            "  Waiting 9.9s before next product...\n",
            "Progress: 3/36\n",
            "Scraping yogurt 6% M.F 750g from Walmart...\n",
            "  Attempting to scrape Walmart price for yogurt 6% M.F 750g...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 8.2 seconds before retry...\n",
            "    SUCCESS: Found price $3.48 on attempt 2\n",
            "  SUCCESS: Live scraped price $3.48\n",
            "  Waiting 9.0s before next product...\n",
            "Progress: 4/36\n",
            "Scraping Coffee Cream 10% Half & Half 1L from Walmart...\n",
            "  Attempting to scrape Walmart price for Coffee Cream 10% Half & Half 1L...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 10.5 seconds before retry...\n",
            "    SUCCESS: Found price $3.77 on attempt 2\n",
            "  SUCCESS: Live scraped price $3.77\n",
            "  Waiting 7.0s before next product...\n",
            "Progress: 5/36\n",
            "Scraping whole chicken from Walmart...\n",
            "  Attempting to scrape Walmart price for whole chicken...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 13.0 seconds before retry...\n",
            "    SUCCESS: Found price $18.58 on attempt 2\n",
            "  SUCCESS: Live scraped price $18.58\n",
            "  Waiting 6.4s before next product...\n",
            "Progress: 6/36\n",
            "Scraping White Bread 675gm from Walmart...\n",
            "  Attempting to scrape Walmart price for White Bread 675gm...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 14.3 seconds before retry...\n",
            "    SUCCESS: Found price $2.48 on attempt 2\n",
            "  SUCCESS: Live scraped price $2.48\n",
            "  Waiting 8.5s before next product...\n",
            "Progress: 7/36\n",
            "Scraping Long Grain Rice 900g from Walmart...\n",
            "  Attempting to scrape Walmart price for Long Grain Rice 900g...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 10.3 seconds before retry...\n",
            "    SUCCESS: Found price $3.47 on attempt 2\n",
            "  SUCCESS: Live scraped price $3.47\n",
            "  Waiting 10.1s before next product...\n",
            "Progress: 8/36\n",
            "Scraping Lean Ground Beef 450gm from Walmart...\n",
            "  Attempting to scrape Walmart price for Lean Ground Beef 450gm...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 10.0 seconds before retry...\n",
            "    SUCCESS: Found price $8.78 on attempt 2\n",
            "  SUCCESS: Live scraped price $8.78\n",
            "  Waiting 5.5s before next product...\n",
            "Progress: 9/36\n",
            "Scraping Bananas from Walmart...\n",
            "  Attempting to scrape Walmart price for Bananas...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 8.9 seconds before retry...\n",
            "    Attempt 2: No valid price found in page content\n",
            "    Attempt 3/3 with different user agent\n",
            "    Waiting 8.5 seconds before retry...\n",
            "    Attempt 3: No valid price found in page content\n",
            "  All Walmart scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $1.75\n",
            "  Waiting 7.9s before next product...\n",
            "Progress: 10/36\n",
            "Scraping Apples from Walmart...\n",
            "  Attempting to scrape Walmart price for Apples...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 11.7 seconds before retry...\n",
            "    SUCCESS: Found price $3.97 on attempt 2\n",
            "  SUCCESS: Live scraped price $3.97\n",
            "  Waiting 10.2s before next product...\n",
            "Progress: 11/36\n",
            "Scraping Potatoes from Walmart...\n",
            "  Attempting to scrape Walmart price for Potatoes...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 10.0 seconds before retry...\n",
            "    SUCCESS: Found price $4.97 on attempt 2\n",
            "  SUCCESS: Live scraped price $4.97\n",
            "  Waiting 7.6s before next product...\n",
            "Progress: 12/36\n",
            "Scraping Cheddar Cheese from Walmart...\n",
            "  Attempting to scrape Walmart price for Cheddar Cheese...\n",
            "  Initializing Walmart session...\n",
            "  Walmart session initialized successfully\n",
            "    Attempt 1/3 with different user agent\n",
            "    Attempt 1: No valid price found in page content\n",
            "    Attempt 2/3 with different user agent\n",
            "    Waiting 15.0 seconds before retry...\n",
            "    SUCCESS: Found price $5.48 on attempt 2\n",
            "  SUCCESS: Live scraped price $5.48\n",
            "  Waiting 7.3s before next product...\n",
            "\n",
            "--- Scraping Metro ---\n",
            "Progress: 13/36\n",
            "Scraping Milk 2% 4L from Metro...\n",
            "  Attempting to scrape Metro price for Milk 2% 4L...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 12.9 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 17.2 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $7.25\n",
            "  Waiting 9.9s before next product...\n",
            "Progress: 14/36\n",
            "Scraping Large Eggs 18-pack from Metro...\n",
            "  Attempting to scrape Metro price for Large Eggs 18-pack...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 17.8 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 12.9 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $8.00\n",
            "  Waiting 12.0s before next product...\n",
            "Progress: 15/36\n",
            "Scraping yogurt 6% M.F 750g from Metro...\n",
            "  Attempting to scrape Metro price for yogurt 6% M.F 750g...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 17.1 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 11.1 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $4.00\n",
            "  Waiting 9.9s before next product...\n",
            "Progress: 16/36\n",
            "Scraping Coffee Cream 10% Half & Half 1L from Metro...\n",
            "  Attempting to scrape Metro price for Coffee Cream 10% Half & Half 1L...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 10.9 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 11.7 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $4.50\n",
            "  Waiting 6.5s before next product...\n",
            "Progress: 17/36\n",
            "Scraping whole chicken from Metro...\n",
            "  Attempting to scrape Metro price for whole chicken...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 17.2 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 15.6 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $20.53\n",
            "  Waiting 10.9s before next product...\n",
            "Progress: 18/36\n",
            "Scraping White Bread 675gm from Metro...\n",
            "  Attempting to scrape Metro price for White Bread 675gm...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 10.3 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 14.8 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $2.25\n",
            "  Waiting 8.4s before next product...\n",
            "Progress: 19/36\n",
            "Scraping Long Grain Rice 900g from Metro...\n",
            "  Attempting to scrape Metro price for Long Grain Rice 900g...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 17.9 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 11.7 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $3.75\n",
            "  Waiting 5.6s before next product...\n",
            "Progress: 20/36\n",
            "Scraping Lean Ground Beef 450gm from Metro...\n",
            "  Attempting to scrape Metro price for Lean Ground Beef 450gm...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 16.2 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 15.2 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $10.00\n",
            "  Waiting 12.0s before next product...\n",
            "Progress: 21/36\n",
            "Scraping Bananas from Metro...\n",
            "  Attempting to scrape Metro price for Bananas...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 16.1 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 15.8 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $2.00\n",
            "  Waiting 10.7s before next product...\n",
            "Progress: 22/36\n",
            "Scraping Apples from Metro...\n",
            "  Attempting to scrape Metro price for Apples...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 12.8 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 10.3 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $6.75\n",
            "  Waiting 7.7s before next product...\n",
            "Progress: 23/36\n",
            "Scraping Potatoes from Metro...\n",
            "  Attempting to scrape Metro price for Potatoes...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 11.1 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 14.9 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $5.75\n",
            "  Waiting 6.1s before next product...\n",
            "Progress: 24/36\n",
            "Scraping Cheddar Cheese from Metro...\n",
            "  Attempting to scrape Metro price for Cheddar Cheese...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 17.9 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 14.1 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Metro scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $5.50\n",
            "  Waiting 6.9s before next product...\n",
            "\n",
            "--- Scraping Loblaws ---\n",
            "Progress: 25/36\n",
            "Scraping Milk 2% 4L from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Milk 2% 4L...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 10.2 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 12.1 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $7.50\n",
            "  Waiting 7.9s before next product...\n",
            "Progress: 26/36\n",
            "Scraping Large Eggs 18-pack from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Large Eggs 18-pack...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 15.6 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 17.5 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $7.75\n",
            "  Waiting 7.2s before next product...\n",
            "Progress: 27/36\n",
            "Scraping yogurt 6% M.F 750g from Loblaws...\n",
            "  Attempting to scrape Loblaws price for yogurt 6% M.F 750g...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 16.7 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 13.9 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $4.25\n",
            "  Waiting 10.7s before next product...\n",
            "Progress: 28/36\n",
            "Scraping Coffee Cream 10% Half & Half 1L from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Coffee Cream 10% Half & Half 1L...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 11.5 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 14.9 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $4.50\n",
            "  Waiting 7.9s before next product...\n",
            "Progress: 29/36\n",
            "Scraping whole chicken from Loblaws...\n",
            "  Attempting to scrape Loblaws price for whole chicken...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 11.1 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 12.0 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $21.73\n",
            "  Waiting 11.8s before next product...\n",
            "Progress: 30/36\n",
            "Scraping White Bread 675gm from Loblaws...\n",
            "  Attempting to scrape Loblaws price for White Bread 675gm...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 10.2 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 15.9 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $2.25\n",
            "  Waiting 7.4s before next product...\n",
            "Progress: 31/36\n",
            "Scraping Long Grain Rice 900g from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Long Grain Rice 900g...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 10.4 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 13.2 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $3.75\n",
            "  Waiting 7.2s before next product...\n",
            "Progress: 32/36\n",
            "Scraping Lean Ground Beef 450gm from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Lean Ground Beef 450gm...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 16.9 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 17.2 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $9.75\n",
            "  Waiting 6.8s before next product...\n",
            "Progress: 33/36\n",
            "Scraping Bananas from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Bananas...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 16.7 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 16.1 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $2.00\n",
            "  Waiting 5.3s before next product...\n",
            "Progress: 34/36\n",
            "Scraping Apples from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Apples...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 14.3 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 15.9 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $7.00\n",
            "  Waiting 11.7s before next product...\n",
            "Progress: 35/36\n",
            "Scraping Potatoes from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Potatoes...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 16.5 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 17.1 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $6.00\n",
            "  Waiting 9.7s before next product...\n",
            "Progress: 36/36\n",
            "Scraping Cheddar Cheese from Loblaws...\n",
            "  Attempting to scrape Loblaws price for Cheddar Cheese...\n",
            "    Attempt 1/3\n",
            "    Attempt 1: HTTP 202\n",
            "    Attempt 2/3\n",
            "    Waiting 16.0 seconds...\n",
            "    Attempt 2: HTTP 202\n",
            "    Attempt 3/3\n",
            "    Waiting 13.0 seconds...\n",
            "    Attempt 3: HTTP 202\n",
            "  All Loblaws scraping attempts failed\n",
            "  Live scraping failed, generating market-based price...\n",
            "  Using market-based price: $5.75\n",
            "\n",
            "============================================================\n",
            "SCRAPING RESULTS SUMMARY\n",
            "============================================================\n",
            "Total products processed: 36\n",
            "Successfully processed: 36\n",
            "Live scraped prices: 11 (30.6%)\n",
            "Market-based simulations: 25 (69.4%)\n",
            "Emergency fallbacks: 0\n",
            "\n",
            "SUCCESS: 11 prices were actually scraped from websites!\n",
            "\n",
            "Successfully scraped prices:\n",
            "  Walmart - Milk 2% 4L: $6.25\n",
            "  Walmart - Large Eggs 18-pack: $6.88\n",
            "  Walmart - yogurt 6% M.F 750g: $3.48\n",
            "  Walmart - Coffee Cream 10% Half & Half 1L: $3.77\n",
            "  Walmart - whole chicken: $18.58\n",
            "\n",
            "Combining current prices with historical simulated data...\n",
            "Total data points: 324 (Historical: 288, Current: 36)\n",
            "\n",
            "Saving combined price data...\n",
            "Loaded 312 historical price records\n",
            "Saved 312 total price records\n",
            "\n",
            "Analyzing price trends with historical context...\n",
            "\n",
            "Generating dynamic inflation analysis report...\n",
            "Prepared 300 monthly price records for analysis\n",
            "Comparing with Statistics Canada CPI data...\n",
            "Fetching Statistics Canada CPI data via vectors...\n",
            "Retrieved 24 Statistics Canada CPI records\n",
            "Prepared 300 monthly price records for analysis\n",
            "\n",
            "Comparison with Statistics Canada:\n",
            "------------------------------------------------------------\n",
            "2025-03: Our   3.0% vs Official   2.3% (diff:  +0.7%)\n",
            "2025-04: Our   3.4% vs Official   1.7% (diff:  +1.7%)\n",
            "2025-05: Our   3.8% vs Official   1.7% (diff:  +2.1%)\n",
            "2025-06: Our   4.3% vs Official   1.9% (diff:  +2.4%)\n",
            "2025-07: Our   3.9% vs Official   1.7% (diff:  +2.2%)\n",
            "2025-08: Our   3.7% vs Official   1.9% (diff:  +1.8%)\n",
            "\n",
            "Exporting comprehensive data for PowerBI...\n",
            "Prepared 300 monthly price records for analysis\n",
            "Exporting Statistics Canada data (guaranteed)...\n",
            "Statistics Canada CPI data exported successfully\n",
            "Grocery basket inflation trends exported\n",
            "Comparing with Statistics Canada CPI data...\n",
            "Fetching Statistics Canada CPI data via vectors...\n",
            "Retrieved 24 Statistics Canada CPI records\n",
            "Prepared 300 monthly price records for analysis\n",
            "\n",
            "Comparison with Statistics Canada:\n",
            "------------------------------------------------------------\n",
            "2025-03: Our   3.0% vs Official   2.3% (diff:  +0.7%)\n",
            "2025-04: Our   3.4% vs Official   1.7% (diff:  +1.7%)\n",
            "2025-05: Our   3.8% vs Official   1.7% (diff:  +2.1%)\n",
            "2025-06: Our   4.3% vs Official   1.9% (diff:  +2.4%)\n",
            "2025-07: Our   3.9% vs Official   1.7% (diff:  +2.2%)\n",
            "2025-08: Our   3.7% vs Official   1.9% (diff:  +1.8%)\n",
            "Tracker vs Statistics Canada comparison exported\n",
            "Product-level inflation analysis exported\n",
            "\n",
            "======================================================================\n",
            "POWERBI FILES CREATED:\n",
            "======================================================================\n",
            " 1. current_prices.csv (36 rows)\n",
            " 2. grocery_basket_inflation_trends.csv (23 rows)\n",
            " 3. monthly_prices.csv (300 rows)\n",
            " 4. price_history.csv (312 rows)\n",
            " 5. product_level_inflation.csv (300 rows)\n",
            " 6. scraping_success_report.csv (5 rows)\n",
            " 7. statistics_canada_cpi.csv (24 rows)\n",
            " 8. tracker_vs_statcan_comparison.csv (22 rows)\n",
            "\n",
            "======================================================================\n",
            "ENHANCED TRACKER ANALYSIS SUMMARY\n",
            "======================================================================\n",
            "Total data points: 312\n",
            "Historical simulated points: 276\n",
            "Current scraped points: 36\n",
            "Products tracked: 12\n",
            "Stores covered: 3\n",
            "Live scraped prices: 11 (3.5%)\n",
            "Market-simulated prices: 25\n",
            "\n",
            "Data Source Breakdown:\n",
            "  historical_simulation: 276 data points\n",
            "  live_scraped: 11 data points\n",
            "  market_simulation: 25 data points\n",
            "\n",
            "Historical vs Current Price Examples:\n",
            "  Milk 2% 4L: $6.00 → $6.25 (+4.2%)\n",
            "  Large Eggs 18-pack: $6.50 → $6.88 (+5.8%)\n",
            "  whole chicken: $17.54 → $18.58 (+5.9%)\n",
            "\n",
            "======================================================================\n",
            "SUCCESS: Complete tracker with guaranteed Statistics Canada export!\n",
            "Real scraping attempts made\n",
            "24 months of historical context based on Statistics Canada inflation\n",
            "Comprehensive CSV files for PowerBI analysis\n",
            "Statistics Canada CPI data guaranteed to export\n"
          ]
        }
      ],
      "source": [
        "# Canadian Online Grocery Price Tracker - COMPLETE FIXED VERSION\n",
        "# Enhanced with historical simulation and guaranteed Statistics Canada export\n",
        "\n",
        "# INSTALL AND IMPORT REQUIRED LIBRARIES\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import json\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"Current date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# REAL PRODUCT URLS FOR CANADIAN RETAILERS\n",
        "\n",
        "REAL_PRODUCT_URLS = {\n",
        "    \"Walmart\": {\n",
        "        \"Milk 2% 4L\": \"https://www.walmart.ca/en/ip/Sealtest-Partly-Skimmed-2-Milk/6000199044832\",\n",
        "        \"Large Eggs 18-pack\": \"https://www.walmart.ca/en/ip/Gray-Ridge-Premium-Large-White-Eggs/6000191268613\",\n",
        "        \"yogurt 6% M.F 750g\": \"https://www.walmart.ca/en/ip/Astro-Original-Balkan-Style-Plain-Yogurt-6/10165982\",\n",
        "        \"Coffee Cream 10% Half & Half 1L\": \"https://www.walmart.ca/en/ip/Great-Value-Half-Half-Cream/6000196187777\",\n",
        "        \"whole chicken\": \"https://www.walmart.ca/en/ip/prime-whole-chicken-raised-without-antibiotics/6000199462076\",\n",
        "        \"White Bread 675gm\": \"https://www.walmart.ca/en/ip/great-value-white-bread/6000206630542\",\n",
        "        \"Long Grain Rice 900g\": \"https://www.walmart.ca/en/ip/Great-Value-Long-Grain-White-Rice/4UD9P76BEQB4\",\n",
        "        \"Lean Ground Beef 450gm\": \"https://www.walmart.ca/en/ip/lean-ground-beef-your-fresh-market/6000191288138\",\n",
        "        \"Bananas\": \"https://www.walmart.ca/en/ip/banana/875806\",\n",
        "        \"Apples\": \"https://www.walmart.ca/en/ip/apple-royal-gala-your-fresh-market/6000197346282\",\n",
        "        \"Potatoes\": \"https://www.walmart.ca/en/ip/your-fresh-market-russet-potatoes/6000196075655\",\n",
        "        \"Cheddar Cheese\": \"https://www.walmart.ca/en/ip/great-value-old-cheddar-cheese/6000208884796\"\n",
        "    },\n",
        "    \"Metro\": {\n",
        "        \"Milk 2% 4L\": \"https://www.instacart.ca/products/19461863-beatrice-2-milk-4-l?retailerSlug=metro\",\n",
        "        \"Large Eggs 18-pack\": \"https://www.instacart.ca/products/27266594-selection-large-white-eggs-18-ct?retailerSlug=metro\",\n",
        "        \"yogurt 6% M.F 750g\": \"https://www.instacart.ca/products/17874024-original-balkan-style-natural-yogurt-750-g?retailerSlug=metro\",\n",
        "        \"Coffee Cream 10% Half & Half 1L\": \"https://www.instacart.ca/products/18454998-lactantia-10-half-half-cream-1-l?retailerSlug=metro\",\n",
        "        \"whole chicken\": \"https://www.instacart.ca/products/27245877-zabiha-whole-chicken-per-kg?retailerSlug=metro\",\n",
        "        \"White Bread 675gm\": \"https://www.instacart.ca/products/17818596-wonder-bread-free-white-bread-675-g?retailerSlug=metro\",\n",
        "        \"Long Grain Rice 900g\": \"https://www.instacart.ca/products/27245111-selection-white-long-grain-rice-900-g?retailerSlug=metro\",\n",
        "        \"Lean Ground Beef 450gm\": \"https://www.instacart.ca/products/30496898-naturalia-lean-ground-beef-454-g?retailerSlug=metro\",\n",
        "        \"Bananas\": \"https://www.instacart.ca/products/2748189-banana-each?retailerSlug=metro\",\n",
        "        \"Apples\": \"https://www.instacart.ca/products/16614400-honeycrisp-apple-each?retailerSlug=metro\",\n",
        "        \"Potatoes\": \"https://www.instacart.ca/products/16417856-russet-potato-bag-5-lbs?retailerSlug=metro\",\n",
        "        \"Cheddar Cheese\": \"https://www.instacart.ca/products/27268458-selection-old-cheddar-colored-cheese-400-g?retailerSlug=metro\"\n",
        "    },\n",
        "    \"Loblaws\": {\n",
        "        \"Milk 2% 4L\": \"https://www.instacart.ca/products/17881458-2-trutaste-milk-4000-ml?retailerSlug=loblaws\",\n",
        "        \"Large Eggs 18-pack\": \"https://www.instacart.ca/products/52088856-conestoga-farms-free-run-eggs-18-pack?retailerSlug=loblaws\",\n",
        "        \"yogurt 6% M.F 750g\": \"https://www.instacart.ca/products/17874024-original-balkan-style-natural-yogurt-750-g?retailerSlug=loblaws\",\n",
        "        \"Coffee Cream 10% Half & Half 1L\": \"https://www.instacart.ca/products/17818861-neilson-10-milk-fat-fresh-half-half-cream-carton-1000-ml?retailerSlug=loblaws\",\n",
        "        \"whole chicken\": \"https://www.instacart.ca/products/75114607-air-chilled-whole-chicken?retailerSlug=loblaws\",\n",
        "        \"White Bread 675gm\": \"https://www.instacart.ca/products/17818596-wonder-bread-free-white-bread-675-g?retailerSlug=loblaws\",\n",
        "        \"Long Grain Rice 900g\": \"https://www.instacart.ca/products/21319248-dainty-foods-royal-white-grain-rice-each?retailerSlug=loblaws\",\n",
        "        \"Lean Ground Beef 450gm\": \"https://www.instacart.ca/products/44685959-lean-ground-beef-450-g?retailerSlug=loblaws\",\n",
        "        \"Bananas\": \"https://www.instacart.ca/products/17327587-banana-bunch-each?retailerSlug=loblaws\",\n",
        "        \"Apples\": \"https://www.instacart.ca/products/20619816-president-s-choice-organic-gala-apples?retailerSlug=loblaws\",\n",
        "        \"Potatoes\": \"https://www.instacart.ca/products/30665693-president-s-choice-russet-potatoes-2-27-kg?retailerSlug=loblaws\",\n",
        "        \"Cheddar Cheese\": \"https://www.instacart.ca/products/21425157-no-name-old-yellow-cheddar-cheese-400-g?retailerSlug=loblaws\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# STATISTICS CANADA API INTEGRATION\n",
        "\n",
        "class StatisticsCanadaAPI:\n",
        "    \"\"\"Fetch real-time inflation data from Statistics Canada.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.base_url = \"https://www150.statcan.gc.ca/t1/wds/rest\"\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (compatible; GroceryTracker/1.0)',\n",
        "            'Accept': 'application/json, text/csv, */*'\n",
        "        })\n",
        "\n",
        "    def fetch_cpi_vectors(self):\n",
        "        \"\"\"Fetch Consumer Price Index data using vector approach.\"\"\"\n",
        "        try:\n",
        "            print(\"Fetching Statistics Canada CPI data via vectors...\")\n",
        "            food_vector = \"41690973\"\n",
        "            vector_url = f\"{self.base_url}/getDataFromVectorsAndLatestNPeriods\"\n",
        "            post_data = [{\"vectorId\": int(food_vector), \"latestN\": 24}]\n",
        "\n",
        "            response = self.session.post(vector_url, json=post_data, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if not data or len(data) == 0:\n",
        "                raise Exception(\"No data returned from Statistics Canada API\")\n",
        "\n",
        "            records = []\n",
        "            for item in data:\n",
        "                if item.get('status') == 'SUCCESS' and 'object' in item:\n",
        "                    obj = item['object']\n",
        "                    if 'vectorDataPoint' in obj:\n",
        "                        for point in obj['vectorDataPoint']:\n",
        "                            records.append({\n",
        "                                'REF_DATE': pd.to_datetime(point['refPer']),\n",
        "                                'VALUE': float(point['value']) if point['value'] else None,\n",
        "                                'Products and product groups': 'Food purchased from stores'\n",
        "                            })\n",
        "\n",
        "            if not records:\n",
        "                raise Exception(\"No valid data points extracted\")\n",
        "\n",
        "            df = pd.DataFrame(records)\n",
        "            df = df.dropna(subset=['VALUE'])\n",
        "            df = df.sort_values('REF_DATE')\n",
        "            df['inflation_yoy'] = df['VALUE'].pct_change(periods=12) * 100\n",
        "\n",
        "            print(f\"Retrieved {len(df)} Statistics Canada CPI records\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch Statistics Canada vector data: {e}\")\n",
        "            return self._fetch_fallback_data()\n",
        "\n",
        "    def fetch_cpi_data(self, table_id=\"18-10-0004-01\"):\n",
        "        \"\"\"Primary method - try vector approach first, fall back to table download.\"\"\"\n",
        "        vector_data = self.fetch_cpi_vectors()\n",
        "        if len(vector_data) > 0:\n",
        "            return vector_data\n",
        "        return self._fetch_fallback_data()\n",
        "\n",
        "    def _fetch_fallback_data(self):\n",
        "        \"\"\"Generate fallback data when API is unavailable.\"\"\"\n",
        "        print(\"Using fallback historical data...\")\n",
        "\n",
        "        statcan_food_inflation = {\n",
        "            \"2024-01\": 3.4, \"2024-02\": 2.4, \"2024-03\": 1.9, \"2024-04\": 1.4,\n",
        "            \"2024-05\": 1.5, \"2024-06\": 2.1, \"2024-07\": 2.1, \"2024-08\": 2.4,\n",
        "            \"2024-09\": 2.4, \"2024-10\": 2.7, \"2024-11\": 2.6, \"2024-12\": 1.9,\n",
        "            \"2025-01\": 1.9, \"2025-02\": 2.8, \"2025-03\": 3.2, \"2025-04\": 3.8,\n",
        "            \"2025-05\": 3.3, \"2025-06\": 2.8, \"2025-07\": 3.4\n",
        "        }\n",
        "\n",
        "        fallback_data = []\n",
        "        base_value = 100.0\n",
        "\n",
        "        for date_str, inflation_rate in statcan_food_inflation.items():\n",
        "            date = pd.to_datetime(date_str, format='%Y-%m')\n",
        "            fallback_data.append({\n",
        "                'REF_DATE': date,\n",
        "                'Products and product groups': 'Food purchased from stores',\n",
        "                'VALUE': base_value,\n",
        "                'inflation_yoy': inflation_rate\n",
        "            })\n",
        "            base_value *= (1 + inflation_rate / 100 / 12)\n",
        "\n",
        "        print(f\"Using {len(fallback_data)} months of actual StatCan food inflation data\")\n",
        "        return pd.DataFrame(fallback_data)\n",
        "\n",
        "# HISTORICAL PRICE SIMULATOR\n",
        "\n",
        "class HistoricalPriceSimulator:\n",
        "    \"\"\"Generate historical prices based on Statistics Canada inflation data.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Current Walmart prices (scraped baseline from September 2025)\n",
        "        self.current_baseline_prices = {\n",
        "            'Milk 2% 4L': 6.25,\n",
        "            'Large Eggs 18-pack': 6.88,\n",
        "            'yogurt 6% M.F 750g': 3.48,\n",
        "            'Coffee Cream 10% Half & Half 1L': 3.77,\n",
        "            'whole chicken': 18.58,\n",
        "            'White Bread 675gm': 1.97,\n",
        "            'Long Grain Rice 900g': 3.27,\n",
        "            'Lean Ground Beef 450gm': 8.46,\n",
        "            'Bananas': 1.68,\n",
        "            'Apples': 5.97,\n",
        "            'Potatoes': 4.97,\n",
        "            'Cheddar Cheese': 4.98\n",
        "        }\n",
        "\n",
        "        # Statistics Canada food inflation rates (year-over-year %)\n",
        "        self.statcan_inflation_rates = {\n",
        "            \"2024-01\": 3.4, \"2024-02\": 2.4, \"2024-03\": 1.9, \"2024-04\": 1.4,\n",
        "            \"2024-05\": 1.5, \"2024-06\": 2.1, \"2024-07\": 2.1, \"2024-08\": 2.4,\n",
        "            \"2024-09\": 2.4, \"2024-10\": 2.7, \"2024-11\": 2.6, \"2024-12\": 1.9,\n",
        "            \"2025-01\": 1.9, \"2025-02\": 2.8, \"2025-03\": 3.2, \"2025-04\": 3.8,\n",
        "            \"2025-05\": 3.3, \"2025-06\": 2.8, \"2025-07\": 3.4\n",
        "        }\n",
        "\n",
        "    def generate_historical_prices(self, months_back=24):\n",
        "        \"\"\"Generate historical prices for all products based on StatCan inflation.\"\"\"\n",
        "        historical_data = []\n",
        "        current_date = datetime.now()\n",
        "\n",
        "        for product_name, current_price in self.current_baseline_prices.items():\n",
        "            product_prices = []\n",
        "            working_price = current_price\n",
        "\n",
        "            # Work backwards from current month\n",
        "            for i in range(months_back):\n",
        "                target_date = current_date - timedelta(days=30*i)\n",
        "                year_month_key = target_date.strftime(\"%Y-%m\")\n",
        "\n",
        "                # Get inflation rate for that month\n",
        "                if year_month_key in self.statcan_inflation_rates:\n",
        "                    monthly_inflation = self.statcan_inflation_rates[year_month_key]\n",
        "                    monthly_rate = monthly_inflation / 12 / 100\n",
        "                else:\n",
        "                    monthly_rate = 2.5 / 12 / 100  # Default average\n",
        "\n",
        "                # Apply product-specific variation\n",
        "                product_variation = self._get_product_inflation_multiplier(product_name)\n",
        "                adjusted_monthly_rate = monthly_rate * product_variation\n",
        "\n",
        "                # Add realistic noise\n",
        "                noise = random.uniform(-0.1, 0.1) * abs(adjusted_monthly_rate)\n",
        "                final_monthly_rate = adjusted_monthly_rate + noise\n",
        "\n",
        "                # Calculate price for this month (working backwards)\n",
        "                if i == 0:\n",
        "                    monthly_price = current_price\n",
        "                else:\n",
        "                    working_price = working_price / (1 + final_monthly_rate)\n",
        "                    monthly_price = working_price\n",
        "\n",
        "                # Ensure realistic price bounds\n",
        "                monthly_price = max(monthly_price, current_price * 0.5)\n",
        "\n",
        "                # Round to realistic pricing\n",
        "                if monthly_price > 10:\n",
        "                    monthly_price = round(monthly_price, 2)\n",
        "                else:\n",
        "                    monthly_price = round(monthly_price * 4) / 4\n",
        "\n",
        "                product_prices.append({\n",
        "                    'product_name': product_name,\n",
        "                    'store_name': 'Walmart',\n",
        "                    'price': monthly_price,\n",
        "                    'scraped_at': target_date,\n",
        "                    'success': True,\n",
        "                    'data_source': 'historical_simulation',\n",
        "                    'scraping_method': 'statcan_inflation_based',\n",
        "                    'year_month': target_date.strftime(\"%Y-%m\"),\n",
        "                    'inflation_rate_used': monthly_inflation if year_month_key in self.statcan_inflation_rates else 2.5\n",
        "                })\n",
        "\n",
        "            historical_data.extend(reversed(product_prices))\n",
        "\n",
        "        return historical_data\n",
        "\n",
        "    def _get_product_inflation_multiplier(self, product_name):\n",
        "        \"\"\"Product-specific inflation multipliers based on food category behavior.\"\"\"\n",
        "        multipliers = {\n",
        "            # Dairy products - track close to average inflation\n",
        "            'Milk 2% 4L': 1.0,\n",
        "            'yogurt 6% M.F 750g': 0.9,\n",
        "            'Coffee Cream 10% Half & Half 1L': 0.95,\n",
        "            'Cheddar Cheese': 1.1,\n",
        "\n",
        "            # Proteins - more volatile, higher inflation\n",
        "            'Large Eggs 18-pack': 1.4,  # Very volatile\n",
        "            'whole chicken': 1.2,\n",
        "            'Lean Ground Beef 450gm': 1.3,\n",
        "\n",
        "            # Staples - more stable pricing\n",
        "            'White Bread 675gm': 0.8,\n",
        "            'Long Grain Rice 900g': 0.9,\n",
        "\n",
        "            # Fresh produce - most volatile\n",
        "            'Bananas': 1.5,\n",
        "            'Apples': 1.3,\n",
        "            'Potatoes': 1.4\n",
        "        }\n",
        "\n",
        "        return multipliers.get(product_name, 1.0)\n",
        "\n",
        "# ENHANCED WEB SCRAPING CLASS\n",
        "\n",
        "class FixedGroceryPriceScraper:\n",
        "    \"\"\"Fixed web scraper that actually attempts to scrape Walmart prices online.\"\"\"\n",
        "\n",
        "    def __init__(self, delay_range=(5, 12)):\n",
        "        \"\"\"Initialize scraper with enhanced anti-detection measures.\"\"\"\n",
        "        self.session = requests.Session()\n",
        "        self.delay_range = delay_range\n",
        "        self.scraping_stats = {\n",
        "            'live_scraped': 0,\n",
        "            'fallback_used': 0,\n",
        "            'failed_completely': 0\n",
        "        }\n",
        "\n",
        "        # Enhanced headers to avoid detection\n",
        "        self.headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "            'Accept-Language': 'en-CA,en-US;q=0.9,en;q=0.8',\n",
        "            'Accept-Encoding': 'gzip, deflate, br',\n",
        "            'DNT': '1',\n",
        "            'Connection': 'keep-alive',\n",
        "            'Upgrade-Insecure-Requests': '1',\n",
        "            'Cache-Control': 'max-age=0'\n",
        "        }\n",
        "        self.session.headers.update(self.headers)\n",
        "        self.price_data = []\n",
        "\n",
        "        # Historical baseline prices (only used as absolute last resort)\n",
        "        self.historical_baseline_prices = {\n",
        "            'milk': 6.25, 'eggs': 6.88, 'yogurt': 3.48, 'cream': 3.77, 'cheese': 4.98,\n",
        "            'chicken': 18.58, 'beef': 8.46, 'bread': 1.97, 'rice': 3.27,\n",
        "            'bananas': 1.68, 'apples': 5.97, 'potatoes': 4.97,\n",
        "        }\n",
        "\n",
        "    def create_walmart_session(self):\n",
        "        \"\"\"Create a specialized session for Walmart scraping.\"\"\"\n",
        "        try:\n",
        "            print(\"  Initializing Walmart session...\")\n",
        "            home_response = self.session.get(\"https://www.walmart.ca\", timeout=20)\n",
        "            home_response.raise_for_status()\n",
        "\n",
        "            self.session.headers.update({\n",
        "                'Referer': 'https://www.walmart.ca/',\n",
        "                'Origin': 'https://www.walmart.ca',\n",
        "                'Host': 'www.walmart.ca'\n",
        "            })\n",
        "\n",
        "            time.sleep(random.uniform(3, 6))\n",
        "            print(\"  Walmart session initialized successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Failed to initialize Walmart session: {e}\")\n",
        "            return False\n",
        "\n",
        "    def attempt_walmart_scraping(self, url, product_name):\n",
        "        \"\"\"Enhanced Walmart-specific scraping with multiple strategies.\"\"\"\n",
        "        print(f\"  Attempting to scrape Walmart price for {product_name}...\")\n",
        "\n",
        "        if not self.create_walmart_session():\n",
        "            print(\"  Failed to create Walmart session, will use fallback\")\n",
        "            return None\n",
        "\n",
        "        walmart_user_agents = [\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
        "        ]\n",
        "\n",
        "        for attempt, user_agent in enumerate(walmart_user_agents, 1):\n",
        "            try:\n",
        "                print(f\"    Attempt {attempt}/{len(walmart_user_agents)} with different user agent\")\n",
        "\n",
        "                self.session.headers.update({'User-Agent': user_agent})\n",
        "\n",
        "                if attempt > 1:\n",
        "                    delay = random.uniform(8, 15)\n",
        "                    print(f\"    Waiting {delay:.1f} seconds before retry...\")\n",
        "                    time.sleep(delay)\n",
        "\n",
        "                response = self.session.get(url, timeout=25)\n",
        "\n",
        "                if response.status_code == 403:\n",
        "                    print(f\"    Attempt {attempt}: 403 Forbidden - Walmart blocking request\")\n",
        "                    continue\n",
        "                elif response.status_code == 429:\n",
        "                    print(f\"    Attempt {attempt}: 429 Too Many Requests - Rate limited\")\n",
        "                    if attempt < len(walmart_user_agents):\n",
        "                        time.sleep(random.uniform(15, 25))\n",
        "                        continue\n",
        "                elif response.status_code != 200:\n",
        "                    print(f\"    Attempt {attempt}: HTTP {response.status_code}\")\n",
        "                    continue\n",
        "\n",
        "                response.raise_for_status()\n",
        "                soup = BeautifulSoup(response.content, 'html.parser')\n",
        "                price = self._extract_walmart_price(soup)\n",
        "\n",
        "                if price and 0.50 < price < 500:\n",
        "                    print(f\"    SUCCESS: Found price ${price:.2f} on attempt {attempt}\")\n",
        "                    self.scraping_stats['live_scraped'] += 1\n",
        "                    return price\n",
        "                else:\n",
        "                    print(f\"    Attempt {attempt}: No valid price found in page content\")\n",
        "\n",
        "            except requests.RequestException as e:\n",
        "                print(f\"    Attempt {attempt} failed: {str(e)[:100]}...\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"    Attempt {attempt} error: {str(e)[:100]}...\")\n",
        "                continue\n",
        "\n",
        "        print(\"  All Walmart scraping attempts failed\")\n",
        "        return None\n",
        "\n",
        "    def _extract_walmart_price(self, soup):\n",
        "        \"\"\"Enhanced price extraction specifically for Walmart.ca.\"\"\"\n",
        "\n",
        "        walmart_price_selectors = [\n",
        "            '[data-automation-id=\"product-price\"] span[itemprop=\"price\"]',\n",
        "            '[data-automation-id=\"product-price\"] .price-display',\n",
        "            '.price-display .visuallyhidden',\n",
        "            '[data-testid=\"price-current\"] span',\n",
        "            '.price-current span',\n",
        "            '.current-price',\n",
        "            '.price-current',\n",
        "            '[itemprop=\"price\"]',\n",
        "            '.price .visuallyhidden',\n",
        "            '[data-automation-id=\"product-price\"]',\n",
        "            '.selling-price-list__item__price',\n",
        "            '.price-block__highlight',\n",
        "            '.price',\n",
        "            '[class*=\"price\"]'\n",
        "        ]\n",
        "\n",
        "        for selector in walmart_price_selectors:\n",
        "            try:\n",
        "                elements = soup.select(selector)\n",
        "                for element in elements:\n",
        "                    text = element.get_text(strip=True)\n",
        "                    if text:\n",
        "                        price = self.extract_price_from_text(text)\n",
        "                        if price and 0.50 < price < 500:\n",
        "                            return price\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Try searching in script tags for JSON data\n",
        "        try:\n",
        "            script_tags = soup.find_all('script', type='application/ld+json')\n",
        "            for script in script_tags:\n",
        "                try:\n",
        "                    data = json.loads(script.string)\n",
        "                    if isinstance(data, dict):\n",
        "                        price = self._extract_price_from_json(data)\n",
        "                        if price and 0.50 < price < 500:\n",
        "                            return price\n",
        "                except:\n",
        "                    continue\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_price_from_json(self, data):\n",
        "        \"\"\"Extract price from JSON structured data.\"\"\"\n",
        "        if isinstance(data, dict):\n",
        "            price_fields = ['price', 'lowPrice', 'highPrice', 'offers']\n",
        "\n",
        "            for field in price_fields:\n",
        "                if field in data:\n",
        "                    if isinstance(data[field], (int, float)):\n",
        "                        return float(data[field])\n",
        "                    elif isinstance(data[field], str):\n",
        "                        price = self.extract_price_from_text(data[field])\n",
        "                        if price:\n",
        "                            return price\n",
        "                    elif isinstance(data[field], dict) and 'price' in data[field]:\n",
        "                        return float(data[field]['price'])\n",
        "\n",
        "            for value in data.values():\n",
        "                if isinstance(value, dict):\n",
        "                    price = self._extract_price_from_json(value)\n",
        "                    if price:\n",
        "                        return price\n",
        "                elif isinstance(value, list):\n",
        "                    for item in value:\n",
        "                        if isinstance(item, dict):\n",
        "                            price = self._extract_price_from_json(item)\n",
        "                            if price:\n",
        "                                return price\n",
        "        return None\n",
        "\n",
        "    def extract_price_from_text(self, text):\n",
        "        \"\"\"Enhanced price extraction with better regex patterns.\"\"\"\n",
        "        if not text:\n",
        "            return None\n",
        "\n",
        "        text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "        price_patterns = [\n",
        "            r'\\$(\\d+(?:\\.\\d{2})?)',\n",
        "            r'CAD\\s*(\\d+(?:\\.\\d{2})?)',\n",
        "            r'C\\$\\s*(\\d+(?:\\.\\d{2})?)',\n",
        "            r'(\\d+)\\.(\\d{2})',\n",
        "            r'(\\d+)\\s*\\.\\s*(\\d{2})',\n",
        "            r'(\\d+)\\s+(\\d{2})',\n",
        "            r'Price:\\s*\\$?(\\d+(?:\\.\\d{2})?)',\n",
        "            r'Current price\\s*\\$?(\\d+(?:\\.\\d{2})?)',\n",
        "        ]\n",
        "\n",
        "        for pattern in price_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                try:\n",
        "                    match = matches[0]\n",
        "                    if isinstance(match, tuple):\n",
        "                        if len(match) == 2:\n",
        "                            dollars, cents = match\n",
        "                            return float(f\"{dollars}.{cents}\")\n",
        "                    else:\n",
        "                        return float(match)\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "        return None\n",
        "\n",
        "    def attempt_generic_scraping(self, url, product_name, store_name):\n",
        "        \"\"\"Generic scraping for non-Walmart retailers.\"\"\"\n",
        "        print(f\"  Attempting to scrape {store_name} price for {product_name}...\")\n",
        "\n",
        "        user_agents = [\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
        "        ]\n",
        "\n",
        "        for attempt, user_agent in enumerate(user_agents, 1):\n",
        "            try:\n",
        "                print(f\"    Attempt {attempt}/{len(user_agents)}\")\n",
        "\n",
        "                self.session.headers.update({'User-Agent': user_agent})\n",
        "\n",
        "                if attempt > 1:\n",
        "                    delay = random.uniform(10, 18)\n",
        "                    print(f\"    Waiting {delay:.1f} seconds...\")\n",
        "                    time.sleep(delay)\n",
        "\n",
        "                response = self.session.get(url, timeout=25)\n",
        "\n",
        "                if response.status_code == 429:\n",
        "                    print(f\"    Attempt {attempt}: Rate limited (429)\")\n",
        "                    if attempt < len(user_agents):\n",
        "                        time.sleep(random.uniform(20, 30))\n",
        "                        continue\n",
        "                elif response.status_code == 403:\n",
        "                    print(f\"    Attempt {attempt}: Access forbidden (403)\")\n",
        "                    continue\n",
        "                elif response.status_code != 200:\n",
        "                    print(f\"    Attempt {attempt}: HTTP {response.status_code}\")\n",
        "                    continue\n",
        "\n",
        "                response.raise_for_status()\n",
        "                soup = BeautifulSoup(response.content, 'html.parser')\n",
        "                price = self._extract_generic_price(soup)\n",
        "\n",
        "                if price and 0.50 < price < 500:\n",
        "                    print(f\"    SUCCESS: Found price ${price:.2f}\")\n",
        "                    self.scraping_stats['live_scraped'] += 1\n",
        "                    return price\n",
        "                else:\n",
        "                    print(f\"    Attempt {attempt}: No valid price found\")\n",
        "\n",
        "            except requests.RequestException as e:\n",
        "                print(f\"    Attempt {attempt} failed: {str(e)[:80]}...\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"    Attempt {attempt} error: {str(e)[:80]}...\")\n",
        "                continue\n",
        "\n",
        "        print(f\"  All {store_name} scraping attempts failed\")\n",
        "        return None\n",
        "\n",
        "    def _extract_generic_price(self, soup):\n",
        "        \"\"\"Generic price extraction for Metro/Loblaws (Instacart).\"\"\"\n",
        "\n",
        "        generic_price_selectors = [\n",
        "            '[data-testid=\"price\"]',\n",
        "            '.css-price span',\n",
        "            '.price-display',\n",
        "            '[class*=\"price\"] span',\n",
        "            '.price', '.price-current', '.current-price',\n",
        "            '.selling-price', '.regular-price', '.sale-price',\n",
        "            '[data-automation-id*=\"price\"]',\n",
        "            '[itemprop=\"price\"]',\n",
        "            '.product-price',\n",
        "            '[class*=\"Price\"]'\n",
        "        ]\n",
        "\n",
        "        for selector in generic_price_selectors:\n",
        "            try:\n",
        "                elements = soup.select(selector)\n",
        "                for element in elements:\n",
        "                    text = element.get_text(strip=True)\n",
        "                    if text:\n",
        "                        price = self.extract_price_from_text(text)\n",
        "                        if price and 0.50 < price < 500:\n",
        "                            return price\n",
        "            except:\n",
        "                continue\n",
        "        return None\n",
        "\n",
        "    def generate_market_based_price(self, product_name, store_name):\n",
        "        \"\"\"Generate realistic market-based prices only as fallback when scraping fails.\"\"\"\n",
        "\n",
        "        store_multipliers = {\n",
        "            'Walmart': 1.0,\n",
        "            'Metro': 1.15,\n",
        "            'Loblaws': 1.18,\n",
        "        }\n",
        "\n",
        "        product_lower = product_name.lower()\n",
        "        base_price = 5.00\n",
        "\n",
        "        for key, price in self.historical_baseline_prices.items():\n",
        "            if key in product_lower:\n",
        "                base_price = price\n",
        "                break\n",
        "\n",
        "        store_multiplier = store_multipliers.get(store_name, 1.1)\n",
        "        adjusted_price = base_price * store_multiplier\n",
        "\n",
        "        variation = random.uniform(-0.04, 0.04)\n",
        "        final_price = adjusted_price * (1 + variation)\n",
        "\n",
        "        if final_price > 10:\n",
        "            final_price = round(final_price, 2)\n",
        "        else:\n",
        "            final_price = round(final_price * 4) / 4\n",
        "\n",
        "        return final_price\n",
        "\n",
        "    def scrape_product_price(self, url, product_name, store_name):\n",
        "        \"\"\"Main scraping method - tries real scraping first, fallback only if needed.\"\"\"\n",
        "        print(f\"Scraping {product_name} from {store_name}...\")\n",
        "\n",
        "        scraped_price = None\n",
        "        data_source = 'failed_scraping'\n",
        "\n",
        "        try:\n",
        "            if 'walmart.ca' in url.lower():\n",
        "                scraped_price = self.attempt_walmart_scraping(url, product_name)\n",
        "            else:\n",
        "                scraped_price = self.attempt_generic_scraping(url, product_name, store_name)\n",
        "\n",
        "            if scraped_price and 0.50 < scraped_price < 500:\n",
        "                print(f\"  SUCCESS: Live scraped price ${scraped_price:.2f}\")\n",
        "                data_source = 'live_scraped'\n",
        "\n",
        "                return {\n",
        "                    'product_name': product_name,\n",
        "                    'store_name': store_name,\n",
        "                    'price': scraped_price,\n",
        "                    'url': url,\n",
        "                    'scraped_at': datetime.now(),\n",
        "                    'success': True,\n",
        "                    'data_source': data_source,\n",
        "                    'scraping_method': 'live_scraping'\n",
        "                }\n",
        "\n",
        "            else:\n",
        "                print(\"  Live scraping failed, generating market-based price...\")\n",
        "                fallback_price = self.generate_market_based_price(product_name, store_name)\n",
        "                data_source = 'market_simulation'\n",
        "                self.scraping_stats['fallback_used'] += 1\n",
        "\n",
        "                print(f\"  Using market-based price: ${fallback_price:.2f}\")\n",
        "\n",
        "                return {\n",
        "                    'product_name': product_name,\n",
        "                    'store_name': store_name,\n",
        "                    'price': fallback_price,\n",
        "                    'url': url,\n",
        "                    'scraped_at': datetime.now(),\n",
        "                    'success': True,\n",
        "                    'data_source': data_source,\n",
        "                    'scraping_method': 'fallback_simulation',\n",
        "                    'note': 'Generated price due to scraping failure'\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Unexpected error: {str(e)[:100]}...\")\n",
        "            fallback_price = self.generate_market_based_price(product_name, store_name)\n",
        "            self.scraping_stats['failed_completely'] += 1\n",
        "\n",
        "            print(f\"  Using emergency fallback price: ${fallback_price:.2f}\")\n",
        "\n",
        "            return {\n",
        "                'product_name': product_name,\n",
        "                'store_name': store_name,\n",
        "                'price': fallback_price,\n",
        "                'url': url,\n",
        "                'scraped_at': datetime.now(),\n",
        "                'success': True,\n",
        "                'data_source': 'emergency_fallback',\n",
        "                'scraping_method': 'emergency_fallback',\n",
        "                'error': str(e)[:200],\n",
        "                'note': 'Emergency fallback due to system error'\n",
        "            }\n",
        "\n",
        "    def scrape_all_products(self, product_urls):\n",
        "        \"\"\"Scrape all products with detailed progress tracking.\"\"\"\n",
        "        print(\"Starting enhanced grocery price scraping...\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        all_results = []\n",
        "        total_products = sum(len(products) for products in product_urls.values())\n",
        "        current_count = 0\n",
        "\n",
        "        for store_name, products in product_urls.items():\n",
        "            print(f\"\\n--- Scraping {store_name} ---\")\n",
        "            self.session.close()\n",
        "            self.session = requests.Session()\n",
        "            self.session.headers.update(self.headers)\n",
        "\n",
        "            for product_name, url in products.items():\n",
        "                current_count += 1\n",
        "                print(f\"Progress: {current_count}/{total_products}\")\n",
        "\n",
        "                result = self.scrape_product_price(url, product_name, store_name)\n",
        "                all_results.append(result)\n",
        "                self.price_data.append(result)\n",
        "                delay = random.uniform(*self.delay_range)\n",
        "                if current_count < total_products:\n",
        "                    print(f\"  Waiting {delay:.1f}s before next product...\")\n",
        "                    time.sleep(delay)\n",
        "\n",
        "        # Print detailed statistics\n",
        "        success_count = sum(1 for r in all_results if r['success'])\n",
        "        live_scraped = sum(1 for r in all_results if r.get('data_source') == 'live_scraped')\n",
        "        market_simulation = sum(1 for r in all_results if r.get('data_source') == 'market_simulation')\n",
        "        emergency_fallback = sum(1 for r in all_results if r.get('data_source') == 'emergency_fallback')\n",
        "\n",
        "        print(f\"\\n\" + \"=\" * 60)\n",
        "        print(\"SCRAPING RESULTS SUMMARY\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Total products processed: {len(all_results)}\")\n",
        "        print(f\"Successfully processed: {success_count}\")\n",
        "        print(f\"Live scraped prices: {live_scraped} ({live_scraped/len(all_results)*100:.1f}%)\")\n",
        "        print(f\"Market-based simulations: {market_simulation} ({market_simulation/len(all_results)*100:.1f}%)\")\n",
        "        print(f\"Emergency fallbacks: {emergency_fallback}\")\n",
        "\n",
        "        if live_scraped > 0:\n",
        "            print(f\"\\nSUCCESS: {live_scraped} prices were actually scraped from websites!\")\n",
        "        else:\n",
        "            print(f\"\\nWARNING: No prices were successfully scraped from websites\")\n",
        "            print(\"   All prices are market-based simulations\")\n",
        "\n",
        "        # Show examples of successfully scraped prices\n",
        "        live_scraped_results = [r for r in all_results if r.get('data_source') == 'live_scraped']\n",
        "        if live_scraped_results:\n",
        "            print(f\"\\nSuccessfully scraped prices:\")\n",
        "            for result in live_scraped_results[:5]:  # Show first 5\n",
        "                print(f\"  {result['store_name']} - {result['product_name']}: ${result['price']:.2f}\")\n",
        "\n",
        "        return all_results\n",
        "\n",
        "# DATA STORAGE AND MANAGEMENT\n",
        "\n",
        "class DynamicDataManager:\n",
        "    \"\"\"Manage persistent storage of price data with historical tracking.\"\"\"\n",
        "\n",
        "    def __init__(self, data_file='data/historical_prices.csv'):\n",
        "        self.data_file = data_file\n",
        "        os.makedirs(os.path.dirname(data_file), exist_ok=True)\n",
        "\n",
        "    def load_historical_data(self):\n",
        "        \"\"\"Load existing historical price data.\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(self.data_file):\n",
        "                df = pd.read_csv(self.data_file)\n",
        "                df['scraped_at'] = pd.to_datetime(df['scraped_at'])\n",
        "                print(f\"Loaded {len(df)} historical price records\")\n",
        "                return df\n",
        "            else:\n",
        "                print(\"No historical data found, starting fresh\")\n",
        "                return pd.DataFrame()\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading historical data: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def append_new_data(self, new_data):\n",
        "        \"\"\"Append new price data to historical records.\"\"\"\n",
        "        if not new_data:\n",
        "            print(\"No new data to append\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Load existing data\n",
        "        historical_df = self.load_historical_data()\n",
        "\n",
        "        # Convert new data to DataFrame\n",
        "        new_df = pd.DataFrame(new_data)\n",
        "        new_df = new_df[new_df['success'] == True]  # Only successful scrapes\n",
        "\n",
        "        if len(new_df) == 0:\n",
        "            print(\"No successful scrapes to save\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Combine and deduplicate\n",
        "        if len(historical_df) > 0:\n",
        "            combined_df = pd.concat([historical_df, new_df], ignore_index=True)\n",
        "        else:\n",
        "            combined_df = new_df\n",
        "\n",
        "        # Remove duplicates based on product, store, and date\n",
        "        combined_df['scraped_date'] = pd.to_datetime(combined_df['scraped_at']).dt.date\n",
        "        combined_df = combined_df.drop_duplicates(\n",
        "            subset=['product_name', 'store_name', 'scraped_date'],\n",
        "            keep='last'\n",
        "        )\n",
        "\n",
        "        # Save updated data\n",
        "        combined_df.to_csv(self.data_file, index=False)\n",
        "        print(f\"Saved {len(combined_df)} total price records\")\n",
        "\n",
        "        return combined_df\n",
        "\n",
        "# ENHANCED INFLATION ANALYSIS\n",
        "\n",
        "class DynamicInflationAnalyzer:\n",
        "    \"\"\"Enhanced inflation analyzer using real price data and Statistics Canada integration.\"\"\"\n",
        "\n",
        "    def __init__(self, price_data, statcan_api=None):\n",
        "        self.price_data = price_data.copy() if len(price_data) > 0 else pd.DataFrame()\n",
        "        self.statcan_api = statcan_api or StatisticsCanadaAPI()\n",
        "        self.official_cpi_data = None\n",
        "\n",
        "    def prepare_price_data(self):\n",
        "        \"\"\"Prepare price data for analysis.\"\"\"\n",
        "        if len(self.price_data) == 0:\n",
        "            print(\"No price data available for analysis\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = self.price_data.copy()\n",
        "        df['scraped_at'] = pd.to_datetime(df['scraped_at'])\n",
        "        df['date'] = df['scraped_at'].dt.date\n",
        "        df['year_month'] = df['scraped_at'].dt.to_period('M')\n",
        "\n",
        "        # Create monthly averages\n",
        "        monthly_data = df.groupby([\n",
        "            'product_name', 'store_name', 'year_month'\n",
        "        ]).agg({\n",
        "            'price': 'mean',\n",
        "            'scraped_at': 'count'\n",
        "        }).round(2)\n",
        "\n",
        "        monthly_data.columns = ['avg_price', 'obs_count']\n",
        "        monthly_data = monthly_data.reset_index()\n",
        "\n",
        "        print(f\"Prepared {len(monthly_data)} monthly price records for analysis\")\n",
        "        return monthly_data\n",
        "\n",
        "    def compare_with_official_cpi(self):\n",
        "        \"\"\"Compare grocery tracker results with official Statistics Canada CPI.\"\"\"\n",
        "        print(\"Comparing with Statistics Canada CPI data...\")\n",
        "\n",
        "        # Fetch official CPI data and store it for export\n",
        "        self.official_cpi_data = self.statcan_api.fetch_cpi_data()\n",
        "\n",
        "        if len(self.official_cpi_data) == 0:\n",
        "            print(\"No official CPI data available for comparison\")\n",
        "            return pd.DataFrame()  # Return empty DataFrame instead of None\n",
        "\n",
        "        # Prepare our data\n",
        "        monthly_data = self.prepare_price_data()\n",
        "        if len(monthly_data) == 0:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Calculate our basket inflation\n",
        "        basket_inflation = monthly_data.groupby('year_month').agg({\n",
        "            'avg_price': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        basket_inflation = basket_inflation.sort_values('year_month')\n",
        "        basket_inflation['our_inflation_yoy'] = basket_inflation['avg_price'].pct_change(periods=12) * 100\n",
        "\n",
        "        # Merge with official data\n",
        "        basket_inflation['date'] = basket_inflation['year_month'].dt.to_timestamp()\n",
        "        official_monthly = self.official_cpi_data.groupby(\n",
        "            self.official_cpi_data['REF_DATE'].dt.to_period('M')\n",
        "        )['inflation_yoy'].mean().reset_index()\n",
        "\n",
        "        official_monthly.columns = ['year_month', 'official_inflation_yoy']\n",
        "\n",
        "        comparison = basket_inflation.merge(\n",
        "            official_monthly, on='year_month', how='inner'\n",
        "        )\n",
        "\n",
        "        if len(comparison) > 0:\n",
        "            comparison['difference'] = comparison['our_inflation_yoy'] - comparison['official_inflation_yoy']\n",
        "\n",
        "            print(\"\\nComparison with Statistics Canada:\")\n",
        "            print(\"-\" * 60)\n",
        "            for _, row in comparison.tail(6).iterrows():\n",
        "                print(f\"{row['year_month']}: Our {row['our_inflation_yoy']:5.1f}% vs Official {row['official_inflation_yoy']:5.1f}% (diff: {row['difference']:+5.1f}%)\")\n",
        "\n",
        "        return comparison\n",
        "\n",
        "    def generate_dynamic_report(self):\n",
        "        \"\"\"Generate comprehensive report with real data.\"\"\"\n",
        "        print(\"\\nGenerating dynamic inflation analysis report...\")\n",
        "\n",
        "        monthly_data = self.prepare_price_data()\n",
        "        comparison_data = self.compare_with_official_cpi()\n",
        "\n",
        "        # Count data sources\n",
        "        live_scraped_count = len(self.price_data[self.price_data.get('data_source', '') == 'live_scraped'])\n",
        "        market_sim_count = len(self.price_data[self.price_data.get('data_source', '') == 'market_simulation'])\n",
        "        historical_sim_count = len(self.price_data[self.price_data.get('data_source', '') == 'historical_simulation'])\n",
        "        emergency_count = len(self.price_data[self.price_data.get('data_source', '') == 'emergency_fallback'])\n",
        "\n",
        "        report = {\n",
        "            'analysis_date': datetime.now(),\n",
        "            'data_summary': {\n",
        "                'total_price_points': len(self.price_data),\n",
        "                'date_range': {\n",
        "                    'start': self.price_data['scraped_at'].min() if len(self.price_data) > 0 else None,\n",
        "                    'end': self.price_data['scraped_at'].max() if len(self.price_data) > 0 else None\n",
        "                },\n",
        "                'products_tracked': len(self.price_data['product_name'].unique()) if len(self.price_data) > 0 else 0,\n",
        "                'stores_covered': len(self.price_data['store_name'].unique()) if len(self.price_data) > 0 else 0,\n",
        "                'live_scraped_prices': live_scraped_count,\n",
        "                'market_simulated_prices': market_sim_count,\n",
        "                'historical_simulated_prices': historical_sim_count,\n",
        "                'emergency_fallback_prices': emergency_count,\n",
        "                'scraping_success_rate': round(live_scraped_count / len(self.price_data) * 100, 1) if len(self.price_data) > 0 else 0\n",
        "            },\n",
        "            'comparison_available': comparison_data is not None and len(comparison_data) > 0\n",
        "        }\n",
        "\n",
        "        if comparison_data is not None and len(comparison_data) > 0:\n",
        "            report['latest_comparison'] = {\n",
        "                'our_inflation': comparison_data['our_inflation_yoy'].iloc[-1],\n",
        "                'official_inflation': comparison_data['official_inflation_yoy'].iloc[-1],\n",
        "                'difference': comparison_data['difference'].iloc[-1]\n",
        "            }\n",
        "\n",
        "        return report\n",
        "\n",
        "# MAIN EXECUTION - COMPLETE FIXED VERSION\n",
        "\n",
        "def run_complete_grocery_tracker():\n",
        "    \"\"\"Execute the complete grocery price tracker with guaranteed Statistics Canada export.\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"COMPLETE CANADIAN GROCERY PRICE TRACKER - WITH GUARANTEED STATCAN EXPORT\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Ensure required directories exist\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    os.makedirs('powerbi_export', exist_ok=True)\n",
        "\n",
        "    # Initialize components\n",
        "    scraper = FixedGroceryPriceScraper()\n",
        "    data_manager = DynamicDataManager()\n",
        "    statcan_api = StatisticsCanadaAPI()\n",
        "    historical_simulator = HistoricalPriceSimulator()\n",
        "\n",
        "    # Load historical data\n",
        "    historical_data = data_manager.load_historical_data()\n",
        "\n",
        "    # Generate historical prices based on Statistics Canada inflation\n",
        "    print(\"\\nGenerating historical prices based on Statistics Canada inflation data...\")\n",
        "    simulated_historical_data = historical_simulator.generate_historical_prices(months_back=24)\n",
        "    print(f\"Generated {len(simulated_historical_data)} historical price points\")\n",
        "\n",
        "    # Scrape current prices\n",
        "    print(\"\\nStarting comprehensive price scraping...\")\n",
        "    print(\"This version will attempt to scrape ALL prices online first\")\n",
        "    print(\"Fallback prices only used when scraping fails\")\n",
        "\n",
        "    new_results = scraper.scrape_all_products(REAL_PRODUCT_URLS)\n",
        "\n",
        "    # Combine current scraped data with historical simulated data\n",
        "    print(\"\\nCombining current prices with historical simulated data...\")\n",
        "    combined_results = simulated_historical_data + new_results\n",
        "    print(f\"Total data points: {len(combined_results)} (Historical: {len(simulated_historical_data)}, Current: {len(new_results)})\")\n",
        "\n",
        "    # Save combined data\n",
        "    print(\"\\nSaving combined price data...\")\n",
        "    updated_data = data_manager.append_new_data(combined_results)\n",
        "\n",
        "    if updated_data is not None and len(updated_data) > 0:\n",
        "        # Perform analysis\n",
        "        print(\"\\nAnalyzing price trends with historical context...\")\n",
        "        analyzer = DynamicInflationAnalyzer(updated_data, statcan_api)\n",
        "        report = analyzer.generate_dynamic_report()\n",
        "\n",
        "        # GUARANTEED STATISTICS CANADA EXPORT\n",
        "        print(\"\\nExporting comprehensive data for PowerBI...\")\n",
        "        monthly_data = analyzer.prepare_price_data()\n",
        "\n",
        "        # Always export basic files\n",
        "        if len(monthly_data) > 0:\n",
        "            # 1. Export monthly data\n",
        "            monthly_data['year_month_str'] = monthly_data['year_month'].astype(str)\n",
        "            monthly_data.to_csv('powerbi_export/monthly_prices.csv', index=False)\n",
        "\n",
        "            # 2. Export current prices\n",
        "            current_prices = updated_data.groupby(['product_name', 'store_name']).tail(1)\n",
        "            current_prices.to_csv('powerbi_export/current_prices.csv', index=False)\n",
        "\n",
        "            # 3. Export price history\n",
        "            price_history = updated_data[['product_name', 'store_name', 'price', 'scraped_at', 'data_source']].copy()\n",
        "            price_history['date'] = pd.to_datetime(price_history['scraped_at']).dt.date\n",
        "            price_history.to_csv('powerbi_export/price_history.csv', index=False)\n",
        "\n",
        "            # 4. Export scraping report\n",
        "            scraping_report = updated_data[['store_name', 'data_source', 'scraping_method']].groupby(['store_name', 'data_source', 'scraping_method']).size().reset_index(name='count')\n",
        "            scraping_report.to_csv('powerbi_export/scraping_success_report.csv', index=False)\n",
        "\n",
        "        # GUARANTEED STATISTICS CANADA EXPORTS\n",
        "        print(\"Exporting Statistics Canada data (guaranteed)...\")\n",
        "\n",
        "        # 5. Always export Statistics Canada CPI data\n",
        "        if hasattr(analyzer, 'official_cpi_data') and analyzer.official_cpi_data is not None and len(analyzer.official_cpi_data) > 0:\n",
        "            statcan_export = analyzer.official_cpi_data.copy()\n",
        "            statcan_export['year'] = statcan_export['REF_DATE'].dt.year\n",
        "            statcan_export['month'] = statcan_export['REF_DATE'].dt.month\n",
        "            statcan_export['year_month'] = statcan_export['REF_DATE'].dt.to_period('M').astype(str)\n",
        "            statcan_export.to_csv('powerbi_export/statistics_canada_cpi.csv', index=False)\n",
        "            print(\"Statistics Canada CPI data exported successfully\")\n",
        "        else:\n",
        "            print(\"No Statistics Canada data available\")\n",
        "\n",
        "        # 6. Always export grocery basket trends\n",
        "        if len(monthly_data) > 0:\n",
        "            basket_trends = monthly_data.groupby('year_month').agg({\n",
        "                'avg_price': ['mean', 'median', 'std', 'count']\n",
        "            }).round(3)\n",
        "            basket_trends.columns = ['basket_avg_price', 'basket_median_price', 'basket_price_std', 'product_count']\n",
        "            basket_trends = basket_trends.reset_index()\n",
        "            basket_trends = basket_trends.sort_values('year_month')\n",
        "\n",
        "            # Calculate inflation rates\n",
        "            basket_trends['our_inflation_mom'] = basket_trends['basket_avg_price'].pct_change() * 100\n",
        "            basket_trends['our_inflation_yoy'] = basket_trends['basket_avg_price'].pct_change(periods=12) * 100\n",
        "            basket_trends['year_month_str'] = basket_trends['year_month'].astype(str)\n",
        "            basket_trends['date'] = basket_trends['year_month'].dt.to_timestamp()\n",
        "            basket_trends['year'] = basket_trends['date'].dt.year\n",
        "            basket_trends['month'] = basket_trends['date'].dt.month\n",
        "            basket_trends.to_csv('powerbi_export/grocery_basket_inflation_trends.csv', index=False)\n",
        "            print(\"Grocery basket inflation trends exported\")\n",
        "\n",
        "        # 7. Export comparison data (if available)\n",
        "        comparison_data = analyzer.compare_with_official_cpi()\n",
        "        if len(comparison_data) > 0:\n",
        "            comparison_export = comparison_data.copy()\n",
        "            comparison_export['year_month_str'] = comparison_export['year_month'].astype(str)\n",
        "            comparison_export['date'] = comparison_export['year_month'].dt.to_timestamp()\n",
        "            comparison_export['year'] = comparison_export['date'].dt.year\n",
        "            comparison_export['month'] = comparison_export['date'].dt.month\n",
        "            comparison_export.to_csv('powerbi_export/tracker_vs_statcan_comparison.csv', index=False)\n",
        "            print(\"Tracker vs Statistics Canada comparison exported\")\n",
        "        else:\n",
        "            print(\"No comparison data available (date mismatch)\")\n",
        "\n",
        "        # 8. Export product-level inflation analysis\n",
        "        if len(monthly_data) > 0:\n",
        "            product_inflation = []\n",
        "            for product in updated_data['product_name'].unique():\n",
        "                product_data = monthly_data[monthly_data['product_name'] == product].copy()\n",
        "                if len(product_data) > 0:\n",
        "                    product_data = product_data.sort_values('year_month')\n",
        "                    product_data['price_change_mom'] = product_data['avg_price'].pct_change() * 100\n",
        "                    product_data['price_change_yoy'] = product_data['avg_price'].pct_change(periods=12) * 100\n",
        "\n",
        "                    for _, row in product_data.iterrows():\n",
        "                        product_inflation.append({\n",
        "                            'product_name': product,\n",
        "                            'year_month': str(row['year_month']),\n",
        "                            'date': row['year_month'].to_timestamp(),\n",
        "                            'avg_price': row['avg_price'],\n",
        "                            'inflation_mom': row['price_change_mom'],\n",
        "                            'inflation_yoy': row['price_change_yoy'],\n",
        "                            'store_count': row['obs_count']\n",
        "                        })\n",
        "\n",
        "            if product_inflation:\n",
        "                product_inflation_df = pd.DataFrame(product_inflation)\n",
        "                product_inflation_df['year'] = product_inflation_df['date'].dt.year\n",
        "                product_inflation_df['month'] = product_inflation_df['date'].dt.month\n",
        "                product_inflation_df.to_csv('powerbi_export/product_level_inflation.csv', index=False)\n",
        "                print(\"Product-level inflation analysis exported\")\n",
        "\n",
        "        # Final summary\n",
        "        print(f\"\\n\" + \"=\" * 70)\n",
        "        print(\"POWERBI FILES CREATED:\")\n",
        "        print(\"=\" * 70)\n",
        "        csv_files = [f for f in os.listdir('powerbi_export') if f.endswith('.csv')]\n",
        "        for i, file in enumerate(sorted(csv_files), 1):\n",
        "            file_path = f\"powerbi_export/{file}\"\n",
        "            if os.path.exists(file_path):\n",
        "                df = pd.read_csv(file_path)\n",
        "                print(f\"{i:2d}. {file} ({len(df)} rows)\")\n",
        "\n",
        "        # Display comprehensive summary\n",
        "        print(f\"\\n\" + \"=\" * 70)\n",
        "        print(\"ENHANCED TRACKER ANALYSIS SUMMARY\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Total data points: {report['data_summary']['total_price_points']}\")\n",
        "        print(f\"Historical simulated points: {report['data_summary']['historical_simulated_prices']}\")\n",
        "        print(f\"Current scraped points: {len(new_results)}\")\n",
        "        print(f\"Products tracked: {report['data_summary']['products_tracked']}\")\n",
        "        print(f\"Stores covered: {report['data_summary']['stores_covered']}\")\n",
        "        print(f\"Live scraped prices: {report['data_summary']['live_scraped_prices']} ({report['data_summary']['scraping_success_rate']}%)\")\n",
        "        print(f\"Market-simulated prices: {report['data_summary']['market_simulated_prices']}\")\n",
        "\n",
        "        # Show data source breakdown including historical simulation\n",
        "        print(f\"\\nData Source Breakdown:\")\n",
        "        source_breakdown = updated_data.groupby(['data_source']).size().reset_index(name='count')\n",
        "        for _, row in source_breakdown.iterrows():\n",
        "            print(f\"  {row['data_source']}: {row['count']} data points\")\n",
        "\n",
        "        # Show historical vs current pricing examples\n",
        "        print(f\"\\nHistorical vs Current Price Examples:\")\n",
        "        for product in ['Milk 2% 4L', 'Large Eggs 18-pack', 'whole chicken']:\n",
        "            current_data = updated_data[\n",
        "                (updated_data['product_name'] == product) &\n",
        "                (updated_data['data_source'].isin(['live_scraped', 'market_simulation']))\n",
        "            ]\n",
        "            historical_data = updated_data[\n",
        "                (updated_data['product_name'] == product) &\n",
        "                (updated_data['data_source'] == 'historical_simulation')\n",
        "            ]\n",
        "\n",
        "            if len(current_data) > 0 and len(historical_data) > 0:\n",
        "                current_price = current_data['price'].iloc[0]\n",
        "                historical_price = historical_data['price'].iloc[0]\n",
        "                price_change = ((current_price - historical_price) / historical_price * 100)\n",
        "                print(f\"  {product}: ${historical_price:.2f} → ${current_price:.2f} ({price_change:+.1f}%)\")\n",
        "\n",
        "        print(f\"\\n\" + \"=\" * 70)\n",
        "        print(\"SUCCESS: Complete tracker with guaranteed Statistics Canada export!\")\n",
        "        print(\"Real scraping attempts made\")\n",
        "        print(\"24 months of historical context based on Statistics Canada inflation\")\n",
        "        print(\"Comprehensive CSV files for PowerBI analysis\")\n",
        "        print(\"Statistics Canada CPI data guaranteed to export\")\n",
        "\n",
        "    else:\n",
        "        print(\"No valid price data collected. Check URLs and network connection.\")\n",
        "\n",
        "# Run the complete tracker\n",
        "if __name__ == \"__main__\":\n",
        "    run_complete_grocery_tracker()"
      ]
    }
  ]
}